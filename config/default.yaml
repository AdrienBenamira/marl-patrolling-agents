agents:
  number_preys: 1
  number_predators: 2

  # For RL
  gamma: 0.9 # Discount factor.
  epsilon_greedy: 0.9 # Probability of exploration.
  lr: 0.01 # Learning rate
  number_actions: 5 # Must be 5 [none, top, left, right, bottom] or 9 with corners added.
  update_frequency: 20 # Update the target net every...
  update_type: hard # Type of update.

replay_memory:
  size: 10000 # Maximum size of the memory.
  shuffle: Yes # If Yes, returns random batches among the elements in the memory. Else always the last ones.

env:
  noise: 0.001 # Agents' actions are not successful with this probability.
  reward_type: full # Must be between full and sparse.
  board_size: 15 # Size of the board
  max_iterations: 50 # Number maximum of steps
  plot_radius: 0.01

learning:
  device: cuda # cuda or cpu
  batch_size: 148
  n_episodes: 500000 # Number of episodes
  save_folder: ./builds/

  plot_episodes_every: 100
  plot_curves_every: 100

  use_model: No # If we load a trained model
  model_path: /path/to/model # path to the trained model

reward:
  coef_distance_reward: 0.001
